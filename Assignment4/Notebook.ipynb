{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.utils import np_utils, generic_utils\n",
    "np.random.seed(2018)  # for reproducibility and comparability, don't change!\n",
    "import json\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load noun-noun compound data\n",
    "def load_data():\n",
    "\tprint(\"Loading data...\")\n",
    "\t# Embeddings\n",
    "\tembeddings = json.load(open('embeddings.json', 'r'))\n",
    "\t# Training and development data\n",
    "\tX_train = []\n",
    "\tY_train = []\n",
    "\twith open('training_data.tsv', 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tsplit = line.strip().split('\\t')\n",
    "\t\t\t# Get feature representation\n",
    "\t\t\tembedding_1 = get_embedding(split[0], embeddings)\n",
    "\t\t\tembedding_2 = get_embedding(split[1], embeddings)\n",
    "\t\t\tX_train.append(embedding_1 + embedding_2)\n",
    "\t\t\t# Get label\n",
    "\t\t\tlabel = split[2]\n",
    "\t\t\tY_train.append(label)\n",
    "\tclasses = sorted(list(set(Y_train)))\n",
    "\tX_train = np.array(X_train)\n",
    "\t# Convert string labels to one-hot vectors\n",
    "\tY_train = label_binarize(Y_train, classes)\n",
    "\tY_train = np.array(Y_train)\n",
    "\t# Split off development set from training data\n",
    "\tX_dev = X_train[-3066:]\n",
    "\tY_dev = Y_train[-3066:]\n",
    "\tX_train = X_train[:-3066]\n",
    "\tY_train = Y_train[:-3066]\n",
    "\tprint(len(X_train), 'training instances')\n",
    "\tprint(len(X_dev), 'develoment instances')\n",
    "\t# Test data\n",
    "\tX_test = []\n",
    "\tY_test = []\n",
    "\twith open('test_data_clean.tsv', 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tsplit = line.strip().split('\\t')\n",
    "\t\t\t# Get feature representation\n",
    "\t\t\tembedding_1 = get_embedding(split[0], embeddings)\n",
    "\t\t\tembedding_2 = get_embedding(split[1], embeddings)\n",
    "\t\t\tX_test.append(embedding_1 + embedding_2)\n",
    "\tX_test = np.array(X_test)\n",
    "\tprint(len(X_test), 'test instances')\n",
    "\n",
    "\treturn X_train, X_dev, X_test, Y_train, Y_dev, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding(word, embeddings):\n",
    "\ttry:\n",
    "\t\t# GloVe embeddings only have lower case words\n",
    "\t\treturn embeddings[word.lower()]\n",
    "\texcept KeyError:\n",
    "\t\treturn embeddings['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build confusion matrix with matplotlib\t\n",
    "def create_confusion_matrix(true, pred):\t\n",
    "\timport matplotlib.pyplot as plt\n",
    "\tfrom sklearn.metrics import confusion_matrix\n",
    "\t# Build matrix\n",
    "\tcm = confusion_matrix(true, pred, labels = classes)\n",
    "\tcm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\t# Make plot\n",
    "\tplt.imshow(cm, interpolation = 'nearest', cmap=plt.cm.Blues)\n",
    "\ttick_marks = np.arange(len(classes))\n",
    "\tplt.xticks(tick_marks, classes, rotation=90)\n",
    "\tplt.xlabel('Predicted label')\n",
    "\tplt.yticks(tick_marks, classes)\n",
    "\tplt.ylabel('True label')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "12261 training instances\n",
      "3066 develoment instances\n",
      "3831 test instances\n",
      "600 features\n",
      "37 classes\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train, X_dev, X_test, Y_train, Y_dev, classes = load_data()\n",
    "nb_features = X_train.shape[1]\n",
    "print(nb_features, 'features')\n",
    "nb_classes = Y_train.shape[1]\n",
    "print(nb_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 64\n",
    "run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12261 samples, validate on 3066 samples\n",
      "Epoch 1/25\n",
      "12261/12261 [==============================] - 19s 2ms/step - loss: 1.5435 - acc: 0.5802 - val_loss: 1.2062 - val_acc: 0.6667\n",
      "Epoch 2/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.8419 - acc: 0.7573 - val_loss: 1.1540 - val_acc: 0.6983\n",
      "Epoch 3/25\n",
      "12261/12261 [==============================] - 17s 1ms/step - loss: 0.5477 - acc: 0.8359 - val_loss: 1.1567 - val_acc: 0.7169\n",
      "Epoch 4/25\n",
      "12261/12261 [==============================] - 21s 2ms/step - loss: 0.3568 - acc: 0.8861 - val_loss: 1.2721 - val_acc: 0.7162\n",
      "Epoch 5/25\n",
      "12261/12261 [==============================] - 19s 2ms/step - loss: 0.2505 - acc: 0.9204 - val_loss: 1.3812 - val_acc: 0.7182\n",
      "Epoch 6/25\n",
      "12261/12261 [==============================] - 17s 1ms/step - loss: 0.1728 - acc: 0.9414 - val_loss: 1.4791 - val_acc: 0.7185\n",
      "Epoch 7/25\n",
      "12261/12261 [==============================] - 18s 1ms/step - loss: 0.1398 - acc: 0.9548 - val_loss: 1.5986 - val_acc: 0.7237\n",
      "Epoch 8/25\n",
      "12261/12261 [==============================] - 21s 2ms/step - loss: 0.1175 - acc: 0.9597 - val_loss: 1.6540 - val_acc: 0.7293\n",
      "Epoch 9/25\n",
      "12261/12261 [==============================] - 23s 2ms/step - loss: 0.0948 - acc: 0.9699 - val_loss: 1.7807 - val_acc: 0.7257\n",
      "Epoch 10/25\n",
      "12261/12261 [==============================] - 17s 1ms/step - loss: 0.0821 - acc: 0.9713 - val_loss: 1.8020 - val_acc: 0.7361\n",
      "Epoch 11/25\n",
      "12261/12261 [==============================] - 20s 2ms/step - loss: 0.0771 - acc: 0.9754 - val_loss: 1.8827 - val_acc: 0.7394\n",
      "Epoch 12/25\n",
      "12261/12261 [==============================] - 20s 2ms/step - loss: 0.0660 - acc: 0.9779 - val_loss: 1.9526 - val_acc: 0.7355\n",
      "Epoch 13/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0591 - acc: 0.9812 - val_loss: 1.9908 - val_acc: 0.7312\n",
      "Epoch 14/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0573 - acc: 0.9820 - val_loss: 2.0962 - val_acc: 0.7326\n",
      "Epoch 15/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0470 - acc: 0.9843 - val_loss: 2.0871 - val_acc: 0.7352\n",
      "Epoch 16/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0500 - acc: 0.9848 - val_loss: 2.1367 - val_acc: 0.7342\n",
      "Epoch 17/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0484 - acc: 0.9854 - val_loss: 2.1533 - val_acc: 0.7358\n",
      "Epoch 18/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0404 - acc: 0.9874 - val_loss: 2.2136 - val_acc: 0.7316\n",
      "Epoch 19/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0402 - acc: 0.9874 - val_loss: 2.2700 - val_acc: 0.7319\n",
      "Epoch 20/25\n",
      "12261/12261 [==============================] - 17s 1ms/step - loss: 0.0376 - acc: 0.9890 - val_loss: 2.2996 - val_acc: 0.7384\n",
      "Epoch 21/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0325 - acc: 0.9901 - val_loss: 2.3322 - val_acc: 0.7358\n",
      "Epoch 22/25\n",
      "12261/12261 [==============================] - 17s 1ms/step - loss: 0.0349 - acc: 0.9902 - val_loss: 2.3221 - val_acc: 0.7407\n",
      "Epoch 23/25\n",
      "12261/12261 [==============================] - 17s 1ms/step - loss: 0.0307 - acc: 0.9907 - val_loss: 2.3709 - val_acc: 0.7368\n",
      "Epoch 24/25\n",
      "12261/12261 [==============================] - 16s 1ms/step - loss: 0.0250 - acc: 0.9918 - val_loss: 2.3715 - val_acc: 0.7436\n",
      "Epoch 25/25\n",
      "12261/12261 [==============================] - 18s 1ms/step - loss: 0.0257 - acc: 0.9921 - val_loss: 2.4467 - val_acc: 0.7387\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Single 500-neuron hidden layer with sigmoid activation\n",
    "model.add(Dense(input_dim = nb_features, units = 5000, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Output layer with softmax activation\n",
    "model.add(Dense(units = nb_classes, activation = 'softmax'))\n",
    "# Specify optimizer, loss and validation metric\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "# Train the model \n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_dev, Y_dev), shuffle=True, verbose=1)\n",
    "\n",
    "# Predict labels for test set\n",
    "outputs = model.predict(X_test, batch_size=batch_size)\n",
    "pred_classes = np.argmax(outputs, axis=1)\n",
    "\n",
    "# Save predictions to file\n",
    "np.save(f'test_set_predictions_run{run}', pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dev_names = [classes[x] for x in np.argmax(Y_dev, axis=1)]\n",
    "pred_dev = model.predict(X_dev, batch_size = batch_size)\n",
    "pred_class_names = [classes[x] for x in np.argmax(pred_dev, axis = 1)]\n",
    "create_confusion_matrix(Y_dev_names, pred_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
